### 1. 基本对象(标量/向量/矩阵/张量)
```python
import torch

a_scalar = torch.tensor(3.0)                 # 标量: shape=()
x_vector = torch.arange(4.0)                 # 向量: shape=(4, )
X_matrix = torch.arange(12.0).reshape(3, 4)  # 矩阵: shape=(3, 4)
T_tensor = torch.randn(2, 3, 4)              # 张量: shape = (2, 3, 4)
````

---

### 2. 点积(dot product)
$$
x ^ \top y = \sum_{i=1}^d x_i y_i
$$

```python
x = torch.arange(4.0)
y = torch.ones(4)

torch.dot(x, y)
(x * y).sum()  # 等价写法
```

---

### 3. 矩阵乘法(matrix multiplication)
$$
(AB)_{ij} = \sum_{k = 1}^n A_{ik} B_{kj}
$$
```python
A = torch.arange(12.0).reshape(3, 4)  # (3, 4)
B = torch.ones(4, 5)  # (4, 5)

A @ B   # (3,5)
```

---

### 4. 范数(norm)
这里和书上写法不太一样 我觉得 X 比 x 更合适
$L_2$范数: $|X|_2 = \sqrt {\sum_i x_i ^ 2}$
$L_1$范数: $|X|_1 = \sum_i |x_i|$
$L_n$范数: $|X|_n = \sqrt[n]{\sum_i x_i ^ n}$ (我猜的 懒得查了)
```python
X = torch.tensor([3.0, 4.0])
# 默认就是L2范数
torch.linalg.norm(X)           # 得数5
torch.linalg.norm(X, ord = 1)  # 得数7
```

---

### 5. 按维求和(后面天天用)
对矩阵 `X.shape=(3, 4)`: 
- `sum(dim = 0)` -> `(4, )`
- `sum(dim = 1)` -> `(3, )`
```python
X = torch.arange(12.0).reshape(3, 4)

# 虽然有不少写法写的是 axis = xxx 但那是numpy pandas上的写法
# pytorch虽然做了映射 但是我感觉写 dim 更好 毕竟维度 dimantion 好理解
X.sum(dim = 0).shape             # (, 4)
X.sum(dim = 1).shape             # (3, )
X.sum(dim = 1, keepdim = True)   # (3,1) 这个写法便于广播
```
